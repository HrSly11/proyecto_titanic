"""
P√°gina de preparaci√≥n de datos
"""
import streamlit as st
import pandas as pd
from src.data.data_loader import load_titanic_data
from src.data.preprocessor import TitanicPreprocessor
from src.visualization.plots import plot_train_test_split
from ui.styles.theme import render_header


def show():
    """Muestra la p√°gina de preparaci√≥n de datos"""
    
    render_header(
        "üõ†Ô∏è Preparaci√≥n de Datos",
        "Limpieza, transformaci√≥n y divisi√≥n de datos"
    )
    
    # Cargar datos
    with st.spinner("Cargando datos..."):
        df = load_titanic_data()
    
    if df is None:
        st.error("Error al cargar datos")
        return
    
    # Tabs para organizar contenido
    tabs = st.tabs([
        "üßπ Limpieza de Datos",
        "üîß Feature Engineering",
        "üìä Codificaci√≥n",
        "‚úÇÔ∏è Divisi√≥n Train/Test",
        "‚úÖ Pipeline Completo"
    ])
    
    # Tab 1: Limpieza de Datos
    with tabs[0]:
        st.subheader("Limpieza de Datos")
        
        st.markdown("""
        Antes de entrenar modelos, necesitamos limpiar los datos:
        - Eliminar columnas innecesarias
        - Manejar valores nulos
        - Tratar outliers si es necesario
        """)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**üìä Datos Originales:**")
            st.dataframe(df.head(5), use_container_width=True)
            st.caption(f"Shape: {df.shape}")
        
        with col2:
            st.markdown("**‚ùå Valores Nulos por Columna:**")
            null_df = pd.DataFrame({
                'Columna': df.columns,
                'Nulos': df.isnull().sum().values,
                'Porcentaje': (df.isnull().sum().values / len(df) * 100).round(2)
            })
            st.dataframe(null_df, use_container_width=True)
        
        st.markdown("---")
        
        # Estrategias de limpieza
        st.subheader("üîß Estrategias de Limpieza")
        
        with st.expander("1Ô∏è‚É£ Eliminar Columnas Innecesarias"):
            st.markdown("""
            **Columnas a eliminar:**
            - `PassengerId`: ID √∫nico, no aporta informaci√≥n predictiva
            - `Name`: Nombres individuales, dif√≠cil de generalizar
            - `Ticket`: N√∫mero de ticket, no relevante para supervivencia
            - `Cabin`: Muchos valores nulos (77%), dif√≠cil de imputar
            """)
            
            st.code("""
columns_to_drop = ['PassengerId', 'Name', 'Ticket', 'Cabin']
df_clean = df.drop(columns=columns_to_drop)
            """, language="python")
        
        with st.expander("2Ô∏è‚É£ Imputar Valores Nulos en Age"):
            st.markdown("""
            **Estrategia**: Usar la **mediana** de la edad
            - Menos sensible a outliers que la media
            - Mantiene la distribuci√≥n central
            """)
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Edad Promedio", f"{df['Age'].mean():.1f} a√±os")
            with col2:
                st.metric("Edad Mediana", f"{df['Age'].median():.1f} a√±os")
            
            st.code("""
df_clean['Age'].fillna(df_clean['Age'].median(), inplace=True)
            """, language="python")
        
        with st.expander("3Ô∏è‚É£ Imputar Valores Nulos en Embarked"):
            st.markdown("""
            **Estrategia**: Usar la **moda** (valor m√°s frecuente)
            - Solo 2 valores nulos
            - La mayor√≠a embarc√≥ en Southampton (S)
            """)
            
            embarked_counts = df['Embarked'].value_counts()
            st.write("**Distribuci√≥n de Embarked:**")
            st.write(embarked_counts)
            
            st.code("""
df_clean['Embarked'].fillna(df_clean['Embarked'].mode()[0], inplace=True)
            """, language="python")
        
        with st.expander("4Ô∏è‚É£ Imputar Valores Nulos en Fare"):
            st.markdown("""
            **Estrategia**: Usar la **mediana** de la tarifa
            - Solo 1 valor nulo
            - Evita distorsi√≥n por tarifas muy altas
            """)
            
            st.code("""
df_clean['Fare'].fillna(df_clean['Fare'].median(), inplace=True)
            """, language="python")
        
        # Aplicar limpieza
        if st.button("üßπ Aplicar Limpieza", type="primary"):
            preprocessor = TitanicPreprocessor()
            df_clean = preprocessor.clean_data(df)
            st.session_state['df_clean'] = df_clean
            
            st.success("‚úÖ Datos limpiados exitosamente")
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Filas Originales", len(df))
            with col2:
                st.metric("Filas Limpias", len(df_clean))
            
            st.dataframe(df_clean.head(), use_container_width=True)
    
    # Tab 2: Feature Engineering
    with tabs[1]:
        st.subheader("Feature Engineering")
        
        st.markdown("""
        **Feature Engineering** es el proceso de crear nuevas caracter√≠sticas o transformar
        las existentes para mejorar el rendimiento del modelo.
        """)
        
        st.info("""
        **üí° Features ya presentes √∫tiles:**
        - `Pclass`: Clase del pasajero (1ra, 2da, 3ra)
        - `Sex`: G√©nero del pasajero
        - `Age`: Edad del pasajero
        - `SibSp`: N√∫mero de hermanos/c√≥nyuges a bordo
        - `Parch`: N√∫mero de padres/hijos a bordo
        - `Fare`: Tarifa pagada
        - `Embarked`: Puerto de embarque
        """)
        
        st.markdown("---")
        
        st.subheader("üé® Ideas de Nuevas Features (Opcionales)")
        
        with st.expander("1Ô∏è‚É£ Family Size (Tama√±o de Familia)"):
            st.markdown("""
            Combinar `SibSp` y `Parch` para obtener el tama√±o total de la familia:
            
            ```python
            df['FamilySize'] = df['SibSp'] + df['Parch'] + 1
            ```
            
            **Hip√≥tesis**: Familias de cierto tama√±o podr√≠an tener mayor probabilidad de supervivencia.
            """)
        
        with st.expander("2Ô∏è‚É£ IsAlone (Viaja Solo)"):
            st.markdown("""
            Indicador binario de si el pasajero viajaba solo:
            
            ```python
            df['IsAlone'] = (df['FamilySize'] == 1).astype(int)
            ```
            
            **Hip√≥tesis**: Pasajeros solos podr√≠an tener diferentes tasas de supervivencia.
            """)
        
        with st.expander("3Ô∏è‚É£ Age Groups (Grupos de Edad)"):
            st.markdown("""
            Categorizar edades en grupos:
            
            ```python
            df['AgeGroup'] = pd.cut(df['Age'], 
                                     bins=[0, 12, 18, 35, 60, 100],
                                     labels=['Child', 'Teen', 'Adult', 'Middle', 'Senior'])
            ```
            
            **Hip√≥tesis**: Diferentes grupos de edad tuvieron diferentes prioridades de evacuaci√≥n.
            """)
        
        with st.expander("4Ô∏è‚É£ Fare Bins (Categor√≠as de Tarifa)"):
            st.markdown("""
            Agrupar tarifas en categor√≠as:
            
            ```python
            df['FareBin'] = pd.qcut(df['Fare'], q=4, labels=['Low', 'Medium', 'High', 'VeryHigh'])
            ```
            
            **Hip√≥tesis**: El precio del ticket correlaciona con la clase y ubicaci√≥n del camarote.
            """)
        
        st.warning("""
        **‚ö†Ô∏è Para este proyecto:**
        
        Usaremos las features originales para mantener la simplicidad y facilitar la interpretaci√≥n.
        Las nuevas features pueden agregarse en iteraciones futuras del modelo.
        """)
    
    # Tab 3: Codificaci√≥n
    with tabs[2]:
        st.subheader("Codificaci√≥n de Variables Categ√≥ricas")
        
        st.markdown("""
        Los algoritmos de ML trabajan con n√∫meros, por lo que debemos convertir
        variables categ√≥ricas a num√©ricas.
        """)
        
        if 'df_clean' not in st.session_state:
            st.warning("‚ö†Ô∏è Primero limpia los datos en la pesta√±a 'Limpieza de Datos'")
        else:
            df_clean = st.session_state['df_clean']
            
            st.markdown("### üî§ Variables Categ√≥ricas a Codificar:")
            
            # Sex
            with st.expander("1Ô∏è‚É£ Sex (G√©nero)"):
                st.markdown("**Label Encoding** - Convertir a binario:")
                
                col1, col2 = st.columns(2)
                with col1:
                    st.write("**Antes:**")
                    st.write(df_clean['Sex'].value_counts())
                with col2:
                    st.write("**Despu√©s:**")
                    st.code("male ‚Üí 0\nfemale ‚Üí 1")
                
                st.code("""
df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})
                """, language="python")
            
            # Embarked
            with st.expander("2Ô∏è‚É£ Embarked (Puerto de Embarque)"):
                st.markdown("**One-Hot Encoding** - Crear columnas dummy:")
                
                st.write("**Antes:**")
                st.write(df_clean['Embarked'].value_counts())
                
                st.write("**Despu√©s:**")
                st.code("""
Embarked_C: [0, 1, 0, ...]
Embarked_Q: [0, 0, 1, ...]
Embarked_S: [1, 0, 0, ...]
                """)
                
                st.code("""
embarked_dummies = pd.get_dummies(df['Embarked'], prefix='Embarked')
df = pd.concat([df, embarked_dummies], axis=1)
df.drop('Embarked', axis=1, inplace=True)
                """, language="python")
            
            # Aplicar codificaci√≥n
            if st.button("üîß Aplicar Codificaci√≥n", type="primary"):
                preprocessor = TitanicPreprocessor()
                df_encoded = preprocessor.encode_features(df_clean)
                st.session_state['df_encoded'] = df_encoded
                
                st.success("‚úÖ Variables codificadas exitosamente")
                
                st.write("**Columnas despu√©s de codificaci√≥n:**")
                st.write(df_encoded.columns.tolist())
                
                st.dataframe(df_encoded.head(), use_container_width=True)
    
    # Tab 4: Divisi√≥n Train/Test
    with tabs[3]:
        st.subheader("Divisi√≥n de Datos: Train/Test")
        
        st.markdown("""
        Dividimos los datos en dos conjuntos:
        - **Train (80%)**: Para entrenar el modelo
        - **Test (20%)**: Para evaluar el rendimiento en datos no vistos
        """)
        
        if 'df_encoded' not in st.session_state:
            st.warning("‚ö†Ô∏è Primero codifica las variables en la pesta√±a 'Codificaci√≥n'")
        else:
            df_encoded = st.session_state['df_encoded']
            
            # Configuraci√≥n de divisi√≥n
            col1, col2 = st.columns(2)
            
            with col1:
                test_size = st.slider(
                    "Porcentaje para Test",
                    min_value=10,
                    max_value=40,
                    value=20,
                    step=5
                ) / 100
            
            with col2:
                random_state = st.number_input(
                    "Random State",
                    min_value=0,
                    value=42
                )
            
            # Aplicar divisi√≥n
            if st.button("‚úÇÔ∏è Dividir Datos", type="primary"):
                preprocessor = TitanicPreprocessor()
                X, y = preprocessor.prepare_features(df_encoded)
                X_train, X_test, y_train, y_test = preprocessor.split_data(
                    X, y, test_size=test_size, random_state=random_state
                )
                
                # Guardar en session_state
                st.session_state['X_train'] = X_train
                st.session_state['X_test'] = X_test
                st.session_state['y_train'] = y_train
                st.session_state['y_test'] = y_test
                st.session_state['feature_names'] = preprocessor.feature_names
                
                st.success("‚úÖ Datos divididos exitosamente")
                
                # Mostrar estad√≠sticas
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("Train Set", len(X_train))
                with col2:
                    st.metric("Test Set", len(X_test))
                with col3:
                    st.metric("Features", len(preprocessor.feature_names))
                with col4:
                    st.metric("Train %", f"{(1-test_size)*100:.0f}%")
                
                # Visualizaci√≥n de la divisi√≥n
                st.plotly_chart(
                    plot_train_test_split(y_train, y_test),
                    use_container_width=True
                )
                
                st.info("""
                **‚úì Balance de Clases:**
                
                Es importante que ambos conjuntos mantengan proporciones similares de
                supervivientes y no supervivientes. Usamos `stratify=y` para garantizar esto.
                """)
    
    # Tab 5: Pipeline Completo
    with tabs[4]:
        st.subheader("Pipeline Completo de Preprocesamiento")
        
        st.markdown("""
        Ejecuta todo el proceso de preparaci√≥n de datos en un solo paso.
        """)
        
        if st.button("üöÄ Ejecutar Pipeline Completo", type="primary", use_container_width=True):
            with st.spinner("Ejecutando pipeline..."):
                # Cargar datos
                df = load_titanic_data()
                
                # Crear preprocessor
                preprocessor = TitanicPreprocessor()
                
                # Pipeline completo
                X_train, X_test, y_train, y_test, df_clean = preprocessor.full_pipeline(df)
                
                # Guardar todo en session_state
                st.session_state['df_clean'] = df_clean
                st.session_state['X_train'] = X_train
                st.session_state['X_test'] = X_test
                st.session_state['y_train'] = y_train
                st.session_state['y_test'] = y_test
                st.session_state['feature_names'] = preprocessor.feature_names
                st.session_state['data_prepared'] = True
                
                st.success("‚úÖ Pipeline ejecutado exitosamente!")
                st.balloons()
                
                # Resumen
                st.markdown("### üìä Resumen del Procesamiento")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**Conjunto de Entrenamiento:**")
                    st.metric("Muestras", len(X_train))
                    st.write("Distribuci√≥n de clases:")
                    st.write(pd.Series(y_train).value_counts())
                
                with col2:
                    st.markdown("**Conjunto de Prueba:**")
                    st.metric("Muestras", len(X_test))
                    st.write("Distribuci√≥n de clases:")
                    st.write(pd.Series(y_test).value_counts())
                
                st.markdown("---")
                
                st.markdown("**Features utilizadas:**")
                st.write(preprocessor.feature_names)
                
                st.info("""
                ‚úì **Datos listos para modelado!**
                
                Ahora puedes proceder a entrenar los modelos en las siguientes secciones:
                - üå≥ √Årbol de Decisi√≥n (Harry)
                - üå≤ Random Forest (Tania)
                """)
    
    # Nota final
    st.markdown("---")
    st.markdown("""
    ## üìù Resumen de Preparaci√≥n
    
    **Pasos completados:**
    1. ‚úÖ Limpieza de datos (eliminaci√≥n de columnas, imputaci√≥n de nulos)
    2. ‚úÖ Codificaci√≥n de variables categ√≥ricas
    3. ‚úÖ Divisi√≥n en conjuntos de entrenamiento y prueba
    4. ‚úÖ Datos listos para modelado
    
    **Siguiente paso:** Entrena los modelos de Machine Learning
    """)