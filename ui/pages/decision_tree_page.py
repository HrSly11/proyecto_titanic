"""
PÃ¡gina del modelo de Ãrbol de DecisiÃ³n
Responsable: Harry Style
"""
import streamlit as st
import pandas as pd
from src.data.data_loader import load_titanic_data
from src.data.preprocessor import TitanicPreprocessor
from src.models.decision_tree import DecisionTreeModel
from src.visualization.tree_viz import (
    plot_decision_tree_matplotlib,
    plot_feature_importance_tree
)
from src.visualization.metrics_viz import plot_confusion_matrix, plot_metrics_comparison
from ui.styles.theme import render_header


def show():
    """Muestra la pÃ¡gina de Ãrbol de DecisiÃ³n"""
    
    render_header(
        "ğŸŒ³ Ãrbol de DecisiÃ³n",
        "ImplementaciÃ³n y anÃ¡lisis del modelo Decision Tree"
    )
    
    st.markdown("""
    ## ğŸ“š IntroducciÃ³n al Ãrbol de DecisiÃ³n
    
    Un **Ãrbol de DecisiÃ³n** es un algoritmo de aprendizaje supervisado que construye un modelo
    de predicciÃ³n en forma de estructura de Ã¡rbol. Divide el dataset en subconjuntos mÃ¡s pequeÃ±os
    basÃ¡ndose en el valor de las caracterÃ­sticas de entrada.
    """)
    
    # Cargar y preparar datos
    with st.spinner("â³ Cargando y preparando datos..."):
        df = load_titanic_data()
        if df is None:
            st.error("Error al cargar datos")
            return
        
        preprocessor = TitanicPreprocessor()
        X_train, X_test, y_train, y_test, df_clean = preprocessor.full_pipeline(df)
        
        # Guardar en session_state
        st.session_state['X_train'] = X_train
        st.session_state['X_test'] = X_test
        st.session_state['y_train'] = y_train
        st.session_state['y_test'] = y_test
        st.session_state['feature_names'] = preprocessor.feature_names
    
    st.success("âœ… Datos preparados exitosamente")
    
    # Tabs para organizar contenido
    tabs = st.tabs([
        "âš™ï¸ ConfiguraciÃ³n",
        "ğŸ“Š Entrenamiento",
        "ğŸŒ³ VisualizaciÃ³n del Ãrbol",
        "ğŸ“ˆ MÃ©tricas",
        "ğŸ” AnÃ¡lisis de Overfitting"
    ])
    
    # Tab 1: ConfiguraciÃ³n
    with tabs[0]:
        st.subheader("ConfiguraciÃ³n del Modelo")
        
        st.markdown("""
        Ajusta los hiperparÃ¡metros del Ã¡rbol de decisiÃ³n. Estos parÃ¡metros controlan
        la complejidad del modelo y pueden ayudar a prevenir el sobreajuste.
        """)
        
        col1, col2 = st.columns(2)
        
        with col1:
            max_depth = st.slider(
                "Profundidad MÃ¡xima del Ãrbol",
                min_value=2,
                max_value=20,
                value=5,
                help="Controla quÃ© tan profundo puede crecer el Ã¡rbol. Mayor profundidad = mayor complejidad."
            )
            
            min_samples_split = st.slider(
                "MÃ­nimo de Muestras para Dividir",
                min_value=2,
                max_value=100,
                value=20,
                help="NÃºmero mÃ­nimo de muestras requeridas para dividir un nodo interno."
            )
        
        with col2:
            min_samples_leaf = st.slider(
                "MÃ­nimo de Muestras en Hoja",
                min_value=1,
                max_value=50,
                value=10,
                help="NÃºmero mÃ­nimo de muestras requeridas en un nodo hoja."
            )
            
            random_state = st.number_input(
                "Random State (Semilla)",
                min_value=0,
                max_value=999,
                value=42,
                help="Semilla para reproducibilidad de resultados."
            )
        
        # InformaciÃ³n sobre parÃ¡metros
        with st.expander("â„¹ï¸ Â¿QuÃ© significan estos parÃ¡metros?"):
            st.markdown("""
            **max_depth**: Limita la profundidad del Ã¡rbol. Ãrboles mÃ¡s profundos pueden capturar
            patrones mÃ¡s complejos pero son mÃ¡s propensos al sobreajuste.
            
            **min_samples_split**: Si un nodo tiene menos muestras que este valor, no se divide.
            Ayuda a prevenir divisiones en grupos muy pequeÃ±os.
            
            **min_samples_leaf**: Garantiza que cada hoja tenga al menos este nÃºmero de muestras.
            Previene hojas con muy pocas observaciones.
            
            **random_state**: Fija la semilla aleatoria para que los resultados sean reproducibles.
            """)
        
        st.session_state['dt_params'] = {
            'max_depth': max_depth,
            'min_samples_split': min_samples_split,
            'min_samples_leaf': min_samples_leaf,
            'random_state': random_state
        }
    
    # Tab 2: Entrenamiento
    with tabs[1]:
        st.subheader("Entrenamiento del Modelo")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Muestras de Entrenamiento", len(X_train))
        with col2:
            st.metric("Muestras de Prueba", len(X_test))
        with col3:
            st.metric("CaracterÃ­sticas", len(preprocessor.feature_names))
        
        st.markdown("---")
        
        if st.button("ğŸš€ Entrenar Modelo", type="primary", use_container_width=True):
            with st.spinner("Entrenando Ã¡rbol de decisiÃ³n..."):
                # Crear y entrenar modelo
                dt_model = DecisionTreeModel(**st.session_state['dt_params'])
                dt_model.train(X_train, y_train)
                
                # Guardar modelo en session_state
                st.session_state['dt_model'] = dt_model
                st.session_state['dt_trained'] = True
                
                st.success("âœ… Modelo entrenado exitosamente!")
                
                # Mostrar informaciÃ³n del Ã¡rbol
                col1, col2 = st.columns(2)
                
                with col1:
                    st.metric("Profundidad Real del Ãrbol", dt_model.get_tree_depth())
                with col2:
                    st.metric("NÃºmero de Hojas", dt_model.get_n_leaves())
                
                st.balloons()
        
        if st.session_state.get('dt_trained', False):
            st.info("âœ“ Modelo ya entrenado. Puedes explorar las demÃ¡s pestaÃ±as.")
    
    # Tab 3: VisualizaciÃ³n del Ãrbol
    with tabs[2]:
        st.subheader("VisualizaciÃ³n del Ãrbol de DecisiÃ³n")
        
        if not st.session_state.get('dt_trained', False):
            st.warning("âš ï¸ Primero debes entrenar el modelo en la pestaÃ±a 'Entrenamiento'")
        else:
            dt_model = st.session_state['dt_model']
            
            st.markdown("""
            Esta visualizaciÃ³n muestra cÃ³mo el Ã¡rbol toma decisiones. Cada nodo representa
            una pregunta sobre una caracterÃ­stica, y las ramas representan las posibles respuestas.
            """)
            
            with st.spinner("Generando visualizaciÃ³n del Ã¡rbol..."):
                try:
                    fig = plot_decision_tree_matplotlib(
                        dt_model.model,
                        feature_names=st.session_state['feature_names']
                    )
                    st.pyplot(fig)
                    
                    st.success("ğŸ’¡ Colores: Naranja = Mayor probabilidad de morir, Azul = Mayor probabilidad de sobrevivir")
                except Exception as e:
                    st.error(f"Error al visualizar Ã¡rbol: {e}")
            
            st.markdown("---")
            
            # Importancia de caracterÃ­sticas
            st.subheader("Importancia de CaracterÃ­sticas")
            
            importance_dict = dt_model.get_feature_importance()
            
            st.plotly_chart(
                plot_feature_importance_tree(importance_dict),
                use_container_width=True
            )
            
            with st.expander("ğŸ“Š Ver valores de importancia"):
                importance_df = pd.DataFrame({
                    'CaracterÃ­stica': importance_dict.keys(),
                    'Importancia': importance_dict.values()
                })
                st.dataframe(importance_df, use_container_width=True)
    
    # Tab 4: MÃ©tricas
    with tabs[3]:
        st.subheader("MÃ©tricas de EvaluaciÃ³n")
        
        if not st.session_state.get('dt_trained', False):
            st.warning("âš ï¸ Primero debes entrenar el modelo en la pestaÃ±a 'Entrenamiento'")
        else:
            dt_model = st.session_state['dt_model']
            
            # Evaluar modelo
            metrics = dt_model.evaluate(X_test, y_test)
            
            # Guardar mÃ©tricas
            st.session_state['dt_metrics'] = metrics
            
            # Mostrar mÃ©tricas principales
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Accuracy", f"{metrics['accuracy']:.3f}")
            with col2:
                st.metric("Precision", f"{metrics['precision']:.3f}")
            with col3:
                st.metric("Recall", f"{metrics['recall']:.3f}")
            with col4:
                st.metric("F1-Score", f"{metrics['f1_score']:.3f}")
            
            st.markdown("---")
            
            # GrÃ¡ficos de mÃ©tricas
            col1, col2 = st.columns(2)
            
            with col1:
                st.plotly_chart(
                    plot_metrics_comparison(metrics, "Decision Tree"),
                    use_container_width=True
                )
            
            with col2:
                st.plotly_chart(
                    plot_confusion_matrix(metrics['confusion_matrix']),
                    use_container_width=True
                )
            
            # Reporte de clasificaciÃ³n
            st.subheader("Reporte de ClasificaciÃ³n Completo")
            st.text(metrics['classification_report'])
            
            # ExplicaciÃ³n de mÃ©tricas
            with st.expander("ğŸ“– Â¿QuÃ© significan estas mÃ©tricas?"):
                st.markdown("""
                **Accuracy**: ProporciÃ³n de predicciones correctas sobre el total.
                
                **Precision**: De todos los que predijimos como sobrevivientes, Â¿cuÃ¡ntos realmente sobrevivieron?
                
                **Recall (Sensibilidad)**: De todos los que realmente sobrevivieron, Â¿cuÃ¡ntos identificamos correctamente?
                
                **F1-Score**: Media armÃ³nica entre precision y recall, Ãºtil cuando las clases estÃ¡n desbalanceadas.
                
                **Matriz de ConfusiÃ³n**:
                - Verdaderos Negativos (TN): Predijimos muerte y murieron
                - Falsos Positivos (FP): Predijimos supervivencia pero murieron
                - Falsos Negativos (FN): Predijimos muerte pero sobrevivieron
                - Verdaderos Positivos (TP): Predijimos supervivencia y sobrevivieron
                """)
    
    # Tab 5: AnÃ¡lisis de Overfitting
    with tabs[4]:
        st.subheader("AnÃ¡lisis de Sobreajuste (Overfitting)")
        
        if not st.session_state.get('dt_trained', False):
            st.warning("âš ï¸ Primero debes entrenar el modelo en la pestaÃ±a 'Entrenamiento'")
        else:
            dt_model = st.session_state['dt_model']
            
            st.markdown("""
            El **overfitting** ocurre cuando un modelo aprende demasiado bien los datos de entrenamiento,
            incluyendo el ruido, lo que resulta en un mal rendimiento en datos nuevos.
            """)
            
            # AnÃ¡lisis de overfitting
            overfitting_analysis = dt_model.analyze_overfitting(X_train, y_train, X_test, y_test)
            
            # MÃ©tricas de comparaciÃ³n
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric(
                    "Accuracy en Train",
                    f"{overfitting_analysis['train_accuracy']:.3f}"
                )
            
            with col2:
                st.metric(
                    "Accuracy en Test",
                    f"{overfitting_analysis['test_accuracy']:.3f}"
                )
            
            with col3:
                delta_color = "inverse" if overfitting_analysis['difference'] > 0.05 else "normal"
                st.metric(
                    "Diferencia",
                    f"{overfitting_analysis['difference']:.3f}",
                    delta=overfitting_analysis['overfitting_level'],
                    delta_color=delta_color
                )
            
            # InterpretaciÃ³n
            if overfitting_analysis['overfitting_level'] == 'Alto':
                st.error(f"ğŸ”´ {overfitting_analysis['description']}")
            elif overfitting_analysis['overfitting_level'] == 'Moderado':
                st.warning(f"ğŸŸ¡ {overfitting_analysis['description']}")
            else:
                st.success(f"ğŸŸ¢ {overfitting_analysis['description']}")
            
            st.markdown("---")
            
            # Recomendaciones
            st.subheader("ğŸ’¡ Recomendaciones para Reducir Overfitting")
            
            st.markdown("""
            Si tu modelo tiene overfitting alto, prueba:
            
            1. **Reducir max_depth**: Limita la profundidad del Ã¡rbol
            2. **Aumentar min_samples_split**: Requiere mÃ¡s muestras para dividir nodos
            3. **Aumentar min_samples_leaf**: Asegura hojas con mÃ¡s muestras
            4. **Usar Random Forest**: El ensemble reduce la varianza
            5. **Podar el Ã¡rbol**: Eliminar ramas que no mejoran significativamente la predicciÃ³n
            """)
            
            # ComparaciÃ³n visual
            st.info("""
            **ğŸ“Š InterpretaciÃ³n de la Diferencia:**
            
            - **< 0.05**: Modelo bien balanceado âœ…
            - **0.05 - 0.10**: Overfitting moderado âš ï¸
            - **> 0.10**: Overfitting alto, ajustar parÃ¡metros âŒ
            """)
    
    # SecciÃ³n final
    st.markdown("---")
    st.markdown("""
    ## ğŸ“ Conclusiones del Ãrbol de DecisiÃ³n
    
    El modelo de Ãrbol de DecisiÃ³n nos permite:
    - âœ… Entender claramente cÃ³mo se toman las decisiones
    - âœ… Identificar las caracterÃ­sticas mÃ¡s importantes
    - âœ… Visualizar el proceso de clasificaciÃ³n
    - âš ï¸ Monitorear el sobreajuste ajustando hiperparÃ¡metros
    
    **Siguiente paso**: Compara este modelo con Random Forest para ver cÃ³mo el ensemble
    mejora el rendimiento y reduce el overfitting.
    """)