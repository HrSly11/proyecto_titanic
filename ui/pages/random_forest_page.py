"""
P√°gina del modelo de Random Forest
Responsable: Tania
"""
import streamlit as st
import pandas as pd
import numpy as np
from src.data.data_loader import load_titanic_data
from src.data.preprocessor import TitanicPreprocessor
from src.models.random_forest import RandomForestModel
from src.visualization.metrics_viz import (
    plot_confusion_matrix,
    plot_metrics_comparison,
    plot_cross_validation_scores,
    plot_feature_importance_comparison
)
from ui.styles.theme import render_header
import plotly.graph_objects as go


def show():
    """Muestra la p√°gina de Random Forest"""
    
    render_header(
        "üå≤ Random Forest",
        "Implementaci√≥n y an√°lisis del modelo Random Forest"
    )
    
    st.markdown("""
    ## üìö Introducci√≥n a Random Forest
    
    **Random Forest** es un algoritmo de *ensemble learning* que combina m√∫ltiples √°rboles
    de decisi√≥n para crear un modelo m√°s robusto y preciso. Cada √°rbol se entrena con una
    muestra aleatoria de los datos (bootstrap) y considera solo un subconjunto aleatorio
    de caracter√≠sticas en cada divisi√≥n.
    
    **Ventajas sobre un solo √°rbol:**
    - ‚úÖ Reduce el sobreajuste mediante promedio de predicciones
    - ‚úÖ M√°s estable ante cambios en los datos
    - ‚úÖ Proporciona estimaciones de importancia de caracter√≠sticas m√°s confiables
    """)
    
    # Cargar y preparar datos
    with st.spinner("‚è≥ Preparando datos..."):
        if 'X_train' not in st.session_state:
            df = load_titanic_data()
            if df is None:
                st.error("Error al cargar datos")
                return
            
            preprocessor = TitanicPreprocessor()
            X_train, X_test, y_train, y_test, df_clean = preprocessor.full_pipeline(df)
            
            st.session_state['X_train'] = X_train
            st.session_state['X_test'] = X_test
            st.session_state['y_train'] = y_train
            st.session_state['y_test'] = y_test
            st.session_state['feature_names'] = preprocessor.feature_names
        else:
            X_train = st.session_state['X_train']
            X_test = st.session_state['X_test']
            y_train = st.session_state['y_train']
            y_test = st.session_state['y_test']
    
    st.success("‚úÖ Datos preparados exitosamente")
    
    # Tabs
    tabs = st.tabs([
        "‚öôÔ∏è Configuraci√≥n",
        "üìä Entrenamiento",
        "üîÑ Validaci√≥n Cruzada",
        "üìà M√©tricas",
        "üéØ Feature Importance",
        "‚öñÔ∏è Comparaci√≥n con DT"
    ])
    
    # Tab 1: Configuraci√≥n
    with tabs[0]:
        st.subheader("Configuraci√≥n de Hiperpar√°metros")
        
        st.markdown("""
        Random Forest tiene varios hiperpar√°metros que controlan el comportamiento del ensemble.
        Ajusta estos valores para optimizar el rendimiento del modelo.
        """)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### üå≤ Par√°metros del Ensemble")
            
            n_estimators = st.slider(
                "N√∫mero de √Årboles (n_estimators)",
                min_value=10,
                max_value=500,
                value=100,
                step=10,
                help="Cantidad de √°rboles en el bosque. M√°s √°rboles = m√°s estable pero m√°s lento."
            )
            
            max_depth = st.slider(
                "Profundidad M√°xima",
                min_value=2,
                max_value=30,
                value=10,
                help="Profundidad m√°xima de cada √°rbol individual."
            )
            
            max_features = st.selectbox(
                "Max Features por Split",
                options=['sqrt', 'log2', None],
                index=0,
                help="N√∫mero m√°ximo de caracter√≠sticas a considerar en cada divisi√≥n."
            )
        
        with col2:
            st.markdown("#### üìä Par√°metros de Control")
            
            min_samples_split = st.slider(
                "Min Samples Split",
                min_value=2,
                max_value=100,
                value=20,
                help="M√≠nimo de muestras para dividir un nodo."
            )
            
            min_samples_leaf = st.slider(
                "Min Samples Leaf",
                min_value=1,
                max_value=50,
                value=5,
                help="M√≠nimo de muestras en cada hoja."
            )
            
            random_state = st.number_input(
                "Random State",
                min_value=0,
                max_value=999,
                value=42,
                help="Semilla para reproducibilidad."
            )
        
        # Informaci√≥n adicional
        with st.expander("‚ÑπÔ∏è Explicaci√≥n de Hiperpar√°metros"):
            st.markdown("""
            **n_estimators**: N√∫mero de √°rboles en el bosque
            - M√°s √°rboles generalmente mejoran el rendimiento
            - Rendimientos decrecientes despu√©s de cierto punto
            - Aumenta el tiempo de entrenamiento linealmente
            
            **max_depth**: Profundidad m√°xima de cada √°rbol
            - Controla la complejidad de cada √°rbol individual
            - Valores muy altos pueden causar overfitting
            - Random Forest es menos sensible que un solo √°rbol
            
            **max_features**: Features a considerar en cada split
            - 'sqrt': Ra√≠z cuadrada del n√∫mero total de features (recomendado para clasificaci√≥n)
            - 'log2': Logaritmo base 2 del n√∫mero de features
            - None: Todas las features (no recomendado)
            
            **min_samples_split/leaf**: Control de tama√±o de nodos
            - Previene divisiones en grupos muy peque√±os
            - Ayuda a reducir overfitting
            """)
        
        # Guardar configuraci√≥n
        st.session_state['rf_params'] = {
            'n_estimators': n_estimators,
            'max_depth': max_depth,
            'min_samples_split': min_samples_split,
            'min_samples_leaf': min_samples_leaf,
            'max_features': max_features,
            'random_state': random_state
        }
        
        st.success("‚úì Configuraci√≥n guardada")
    
    # Tab 2: Entrenamiento
    with tabs[1]:
        st.subheader("Entrenamiento del Modelo")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Muestras Train", len(X_train))
        with col2:
            st.metric("Muestras Test", len(X_test))
        with col3:
            st.metric("Features", len(st.session_state.get('feature_names', [])))
        
        st.markdown("---")
        
        if st.button("üöÄ Entrenar Random Forest", type="primary", use_container_width=True):
            with st.spinner("Entrenando Random Forest... Esto puede tomar unos segundos."):
                # Crear y entrenar modelo
                rf_model = RandomForestModel(**st.session_state['rf_params'])
                rf_model.train(X_train, y_train)
                
                # Guardar en session_state
                st.session_state['rf_model'] = rf_model
                st.session_state['rf_trained'] = True
                
                st.success("‚úÖ Random Forest entrenado exitosamente!")
                st.balloons()
                
                # Informaci√≥n del ensemble
                ensemble_info = rf_model.analyze_ensemble()
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("√Årboles en Bosque", ensemble_info['n_estimators'])
                with col2:
                    st.metric("Profundidad M√°xima", ensemble_info['max_depth'])
                with col3:
                    st.metric("Features Usadas", ensemble_info['n_features'])
                with col4:
                    st.metric("Clases", ensemble_info['n_classes'])
        
        if st.session_state.get('rf_trained', False):
            st.info("‚úì Modelo entrenado. Explora las dem√°s pesta√±as para an√°lisis detallado.")
    
    # Tab 3: Validaci√≥n Cruzada
    with tabs[2]:
        st.subheader("Validaci√≥n Cruzada")
        
        if not st.session_state.get('rf_trained', False):
            st.warning("‚ö†Ô∏è Primero entrena el modelo en la pesta√±a 'Entrenamiento'")
        else:
            st.markdown("""
            La **validaci√≥n cruzada** divide los datos en K partes (folds) y entrena
            el modelo K veces, usando cada vez una parte diferente como test.
            Esto proporciona una estimaci√≥n m√°s robusta del rendimiento.
            """)
            
            cv_folds = st.slider(
                "N√∫mero de Folds",
                min_value=3,
                max_value=10,
                value=5,
                help="N√∫mero de divisiones para validaci√≥n cruzada (K-Fold CV)"
            )
            
            if st.button("üîÑ Ejecutar Validaci√≥n Cruzada", type="primary"):
                with st.spinner(f"Ejecutando {cv_folds}-Fold Cross Validation..."):
                    rf_model = st.session_state['rf_model']
                    
                    # Realizar validaci√≥n cruzada
                    cv_results = rf_model.cross_validate(
                        pd.concat([X_train, X_test]),
                        pd.concat([y_train, y_test]),
                        cv=cv_folds
                    )
                    
                    st.session_state['cv_results'] = cv_results
                    
                    st.success("‚úÖ Validaci√≥n cruzada completada!")
                    
                    # M√©tricas de CV
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("Score Promedio", f"{cv_results['mean_score']:.4f}")
                    with col2:
                        st.metric("Desv. Est√°ndar", f"{cv_results['std_score']:.4f}")
                    with col3:
                        st.metric("Score M√≠nimo", f"{cv_results['min_score']:.4f}")
                    with col4:
                        st.metric("Score M√°ximo", f"{cv_results['max_score']:.4f}")
                    
                    # Gr√°fico de CV
                    st.plotly_chart(
                        plot_cross_validation_scores(cv_results['scores']),
                        use_container_width=True
                    )
                    
                    st.info(f"""
                    **Interpretaci√≥n:**
                    
                    - Una desviaci√≥n est√°ndar baja ({cv_results['std_score']:.4f}) indica que el modelo
                      es estable y consistente en diferentes subconjuntos de datos.
                    - El score promedio ({cv_results['mean_score']:.4f}) es una estimaci√≥n m√°s confiable
                      del rendimiento real que un solo train/test split.
                    """)
    
    # Tab 4: M√©tricas
    with tabs[3]:
        st.subheader("M√©tricas de Evaluaci√≥n")
        
        if not st.session_state.get('rf_trained', False):
            st.warning("‚ö†Ô∏è Primero entrena el modelo en la pesta√±a 'Entrenamiento'")
        else:
            rf_model = st.session_state['rf_model']
            
            # Evaluar modelo
            metrics = rf_model.evaluate(X_test, y_test)
            st.session_state['rf_metrics'] = metrics
            
            # M√©tricas principales
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Accuracy", f"{metrics['accuracy']:.3f}")
            with col2:
                st.metric("Precision", f"{metrics['precision']:.3f}")
            with col3:
                st.metric("Recall", f"{metrics['recall']:.3f}")
            with col4:
                st.metric("F1-Score", f"{metrics['f1_score']:.3f}")
            
            st.markdown("---")
            
            # Gr√°ficos
            col1, col2 = st.columns(2)
            
            with col1:
                st.plotly_chart(
                    plot_metrics_comparison(metrics, "Random Forest"),
                    use_container_width=True
                )
            
            with col2:
                st.plotly_chart(
                    plot_confusion_matrix(metrics['confusion_matrix'], title="Matriz de Confusi√≥n - RF"),
                    use_container_width=True
                )
            
            # Reporte detallado
            st.subheader("Reporte de Clasificaci√≥n")
            st.text(metrics['classification_report'])
            
            # An√°lisis Train vs Test
            st.markdown("---")
            st.subheader("An√°lisis de Generalization")
            
            train_score = rf_model.model.score(X_train, y_train)
            test_score = metrics['accuracy']
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Train Accuracy", f"{train_score:.3f}")
            with col2:
                st.metric("Test Accuracy", f"{test_score:.3f}")
            with col3:
                diff = train_score - test_score
                st.metric("Diferencia", f"{diff:.3f}")
            
            if diff < 0.03:
                st.success("üü¢ Excelente generalizaci√≥n! El modelo no est√° sobreajustado.")
            elif diff < 0.07:
                st.info("üü° Buena generalizaci√≥n. Diferencia aceptable entre train y test.")
            else:
                st.warning("üü† Posible sobreajuste. Considera ajustar hiperpar√°metros.")
    
    # Tab 5: Feature Importance
    with tabs[4]:
        st.subheader("Importancia de Caracter√≠sticas")
        
        if not st.session_state.get('rf_trained', False):
            st.warning("‚ö†Ô∏è Primero entrena el modelo en la pesta√±a 'Entrenamiento'")
        else:
            rf_model = st.session_state['rf_model']
            
            st.markdown("""
            Random Forest calcula la importancia de cada caracter√≠stica bas√°ndose en
            cu√°nto reducen la impureza (Gini) en promedio a trav√©s de todos los √°rboles.
            """)
            
            # Obtener importancias
            importance_dict = rf_model.get_feature_importance()
            
            # Gr√°fico de importancia
            features = list(importance_dict.keys())
            importances = list(importance_dict.values())
            
            fig = go.Figure(go.Bar(
                x=importances,
                y=features,
                orientation='h',
                marker=dict(
                    color=importances,
                    colorscale='Viridis',
                    showscale=True,
                    colorbar=dict(title="Importancia")
                ),
                text=[f'{imp:.4f}' for imp in importances],
                textposition='auto'
            ))
            
            fig.update_layout(
                title='Importancia de Caracter√≠sticas - Random Forest',
                xaxis_title='Importancia',
                yaxis_title='Caracter√≠stica',
                template='plotly_white',
                height=max(400, len(features) * 30)
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Tabla de importancias
            with st.expander("üìä Ver tabla de importancias"):
                importance_df = pd.DataFrame({
                    'Caracter√≠stica': features,
                    'Importancia': importances,
                    'Porcentaje': [f"{imp*100:.2f}%" for imp in importances]
                })
                st.dataframe(importance_df, use_container_width=True)
            
            # Top 3 features
            st.markdown("### üèÜ Top 3 Caracter√≠sticas M√°s Importantes")
            top3 = list(importance_dict.items())[:3]
            
            cols = st.columns(3)
            for i, (feature, importance) in enumerate(top3):
                with cols[i]:
                    st.metric(
                        f"#{i+1} {feature}",
                        f"{importance:.4f}",
                        f"{importance*100:.2f}%"
                    )
    
    # Tab 6: Comparaci√≥n con DT
    with tabs[5]:
        st.subheader("Comparaci√≥n: Random Forest vs Decision Tree")
        
        if not st.session_state.get('rf_trained', False):
            st.warning("‚ö†Ô∏è Primero entrena el modelo Random Forest")
        elif not st.session_state.get('dt_trained', False):
            st.warning("‚ö†Ô∏è Tambi√©n necesitas entrenar el Decision Tree en su secci√≥n")
        else:
            st.markdown("""
            Comparaci√≥n directa entre el modelo individual (Decision Tree) y el ensemble (Random Forest).
            """)
            
            rf_metrics = st.session_state['rf_metrics']
            dt_metrics = st.session_state['dt_metrics']
            
            # Tabla comparativa
            st.markdown("### üìä Tabla Comparativa de M√©tricas")
            
            comparison_df = pd.DataFrame({
                'M√©trica': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],
                'Decision Tree': [
                    dt_metrics['accuracy'],
                    dt_metrics['precision'],
                    dt_metrics['recall'],
                    dt_metrics['f1_score']
                ],
                'Random Forest': [
                    rf_metrics['accuracy'],
                    rf_metrics['precision'],
                    rf_metrics['recall'],
                    rf_metrics['f1_score']
                ]
            })
            
            comparison_df['Mejora (%)'] = (
                (comparison_df['Random Forest'] - comparison_df['Decision Tree']) / 
                comparison_df['Decision Tree'] * 100
            ).round(2)
            
            st.dataframe(
                comparison_df.style.format({
                    'Decision Tree': '{:.4f}',
                    'Random Forest': '{:.4f}',
                    'Mejora (%)': '{:+.2f}%'
                }).background_gradient(subset=['Mejora (%)'], cmap='RdYlGn'),
                use_container_width=True
            )
            
            # Gr√°fico comparativo
            from src.visualization.metrics_viz import plot_models_comparison
            st.plotly_chart(
                plot_models_comparison(dt_metrics, rf_metrics),
                use_container_width=True
            )
            
            # Comparaci√≥n de Feature Importance
            st.markdown("---")
            st.markdown("### üéØ Comparaci√≥n de Feature Importance")
            
            dt_importance = st.session_state['dt_model'].get_feature_importance()
            rf_importance = rf_model.get_feature_importance()
            
            st.plotly_chart(
                plot_feature_importance_comparison(dt_importance, rf_importance),
                use_container_width=True
            )
            
            # Conclusiones
            st.markdown("---")
            st.markdown("### üìù Conclusiones")
            
            winner = "Random Forest" if rf_metrics['accuracy'] > dt_metrics['accuracy'] else "Decision Tree"
            
            st.success(f"""
            **üèÜ Modelo Ganador: {winner}**
            
            **Resumen de comparaci√≥n:**
            - Random Forest {'supera' if rf_metrics['accuracy'] > dt_metrics['accuracy'] else 'es similar a'} Decision Tree en accuracy
            - El ensemble reduce el overfitting y mejora la estabilidad
            - Random Forest proporciona estimaciones m√°s confiables de feature importance
            - El costo es mayor tiempo de entrenamiento y menor interpretabilidad
            """)
            
            st.info("""
            **üí° Recomendaciones:**
            
            - **Usa Decision Tree** si necesitas interpretabilidad m√°xima y un modelo simple
            - **Usa Random Forest** si priorizas rendimiento y robustez sobre interpretabilidad
            - Para producci√≥n, Random Forest suele ser la mejor opci√≥n
            """)