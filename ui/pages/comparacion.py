"""
P√°gina de comparaci√≥n de modelos
"""
import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from src.visualization.metrics_viz import plot_models_comparison, plot_feature_importance_comparison
from ui.styles.theme import render_header


def show():
    """Muestra la p√°gina de comparaci√≥n"""
    
    render_header(
        "‚öñÔ∏è Comparaci√≥n de Modelos",
        "An√°lisis comparativo entre Decision Tree y Random Forest"
    )
    
    # Verificar que ambos modelos est√©n entrenados
    if not st.session_state.get('dt_trained', False):
        st.error("‚ùå Primero entrena el modelo Decision Tree en su secci√≥n")
        return
    
    if not st.session_state.get('rf_trained', False):
        st.error("‚ùå Primero entrena el modelo Random Forest en su secci√≥n")
        return
    
    st.success("‚úÖ Ambos modelos est√°n entrenados y listos para comparar")
    
    # Obtener m√©tricas de ambos modelos
    dt_metrics = st.session_state['dt_metrics']
    rf_metrics = st.session_state['rf_metrics']
    
    # Tabs para organizar contenido
    tabs = st.tabs([
        "üìä Resumen Ejecutivo",
        "üìà M√©tricas Detalladas",
        "üéØ Feature Importance",
        "‚è±Ô∏è Rendimiento",
        "üí° Conclusiones"
    ])
    
    # Tab 1: Resumen Ejecutivo
    with tabs[0]:
        st.subheader("Resumen Ejecutivo")
        
        # KPIs principales
        st.markdown("### üéØ M√©tricas Principales")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### üå≥ Decision Tree")
            dt_col1, dt_col2 = st.columns(2)
            with dt_col1:
                st.metric("Accuracy", f"{dt_metrics['accuracy']:.3f}")
                st.metric("Precision", f"{dt_metrics['precision']:.3f}")
            with dt_col2:
                st.metric("Recall", f"{dt_metrics['recall']:.3f}")
                st.metric("F1-Score", f"{dt_metrics['f1_score']:.3f}")
        
        with col2:
            st.markdown("#### üå≤ Random Forest")
            rf_col1, rf_col2 = st.columns(2)
            with rf_col1:
                st.metric(
                    "Accuracy", 
                    f"{rf_metrics['accuracy']:.3f}",
                    delta=f"{(rf_metrics['accuracy'] - dt_metrics['accuracy']):.3f}"
                )
                st.metric(
                    "Precision", 
                    f"{rf_metrics['precision']:.3f}",
                    delta=f"{(rf_metrics['precision'] - dt_metrics['precision']):.3f}"
                )
            with rf_col2:
                st.metric(
                    "Recall", 
                    f"{rf_metrics['recall']:.3f}",
                    delta=f"{(rf_metrics['recall'] - dt_metrics['recall']):.3f}"
                )
                st.metric(
                    "F1-Score", 
                    f"{rf_metrics['f1_score']:.3f}",
                    delta=f"{(rf_metrics['f1_score'] - dt_metrics['f1_score']):.3f}"
                )
        
        st.markdown("---")
        
        # Ganador
        st.markdown("### üèÜ Modelo Ganador")
        
        winner_accuracy = "Random Forest" if rf_metrics['accuracy'] > dt_metrics['accuracy'] else "Decision Tree"
        winner_f1 = "Random Forest" if rf_metrics['f1_score'] > dt_metrics['f1_score'] else "Decision Tree"
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if rf_metrics['accuracy'] > dt_metrics['accuracy']:
                st.success(f"üèÜ **{winner_accuracy}**\nMejor Accuracy")
            elif dt_metrics['accuracy'] > rf_metrics['accuracy']:
                st.info(f"üèÜ **{winner_accuracy}**\nMejor Accuracy")
            else:
                st.warning("ü§ù **Empate**\nMisma Accuracy")
        
        with col2:
            if rf_metrics['f1_score'] > dt_metrics['f1_score']:
                st.success(f"üèÜ **{winner_f1}**\nMejor F1-Score")
            elif dt_metrics['f1_score'] > rf_metrics['f1_score']:
                st.info(f"üèÜ **{winner_f1}**\nMejor F1-Score")
            else:
                st.warning("ü§ù **Empate**\nMismo F1-Score")
        
        with col3:
            # Modelo m√°s balanceado
            dt_balance = abs(dt_metrics['precision'] - dt_metrics['recall'])
            rf_balance = abs(rf_metrics['precision'] - rf_metrics['recall'])
            
            if rf_balance < dt_balance:
                st.success("üèÜ **Random Forest**\nM√°s Balanceado")
            else:
                st.info("üèÜ **Decision Tree**\nM√°s Balanceado")
        
        st.markdown("---")
        
        # Quick insights
        st.markdown("### üí° Insights R√°pidos")
        
        mejora_accuracy = ((rf_metrics['accuracy'] - dt_metrics['accuracy']) / dt_metrics['accuracy']) * 100
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.info(f"""
            **üìä Mejora en Accuracy:**
            
            Random Forest {'mejora' if mejora_accuracy > 0 else 'reduce'} el accuracy en **{abs(mejora_accuracy):.2f}%** 
            comparado con Decision Tree.
            """)
        
        with col2:
            if 'cv_results' in st.session_state:
                cv_std = st.session_state['cv_results']['std_score']
                st.info(f"""
                **üîÑ Estabilidad (CV):**
                
                Random Forest tiene una desviaci√≥n est√°ndar de **{cv_std:.4f}** en validaci√≥n cruzada,
                indicando {'alta' if cv_std < 0.02 else 'moderada'} estabilidad.
                """)
            else:
                st.info("""
                **üîÑ Estabilidad:**
                
                Random Forest generalmente es m√°s estable gracias al ensemble de m√∫ltiples √°rboles.
                """)
    
    # Tab 2: M√©tricas Detalladas
    with tabs[1]:
        st.subheader("An√°lisis Detallado de M√©tricas")
        
        # Gr√°fico comparativo
        st.plotly_chart(
            plot_models_comparison(dt_metrics, rf_metrics),
            use_container_width=True
        )
        
        st.markdown("---")
        
        # Tabla comparativa detallada
        st.markdown("### üìã Tabla Comparativa Completa")
        
        comparison_data = {
            'M√©trica': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 
                       'True Negatives', 'False Positives', 'False Negatives', 'True Positives'],
            'Decision Tree': [
                dt_metrics['accuracy'],
                dt_metrics['precision'],
                dt_metrics['recall'],
                dt_metrics['f1_score'],
                dt_metrics['confusion_matrix'][0][0],
                dt_metrics['confusion_matrix'][0][1],
                dt_metrics['confusion_matrix'][1][0],
                dt_metrics['confusion_matrix'][1][1]
            ],
            'Random Forest': [
                rf_metrics['accuracy'],
                rf_metrics['precision'],
                rf_metrics['recall'],
                rf_metrics['f1_score'],
                rf_metrics['confusion_matrix'][0][0],
                rf_metrics['confusion_matrix'][0][1],
                rf_metrics['confusion_matrix'][1][0],
                rf_metrics['confusion_matrix'][1][1]
            ]
        }
        
        comparison_df = pd.DataFrame(comparison_data)
        
        # Calcular diferencias
        comparison_df['Diferencia'] = comparison_df['Random Forest'] - comparison_df['Decision Tree']
        comparison_df['Mejora (%)'] = (
            (comparison_df['Random Forest'] - comparison_df['Decision Tree']) / 
            comparison_df['Decision Tree'] * 100
        ).round(2)
        
        # Aplicar formato
        styled_df = comparison_df.style.format({
            'Decision Tree': lambda x: f'{x:.4f}' if x < 2 else f'{int(x)}',
            'Random Forest': lambda x: f'{x:.4f}' if x < 2 else f'{int(x)}',
            'Diferencia': lambda x: f'{x:+.4f}' if abs(x) < 2 else f'{int(x):+d}',
            'Mejora (%)': '{:+.2f}%'
        })
        
        st.dataframe(styled_df, use_container_width=True)
        
        st.markdown("---")
        
        # An√°lisis de Confusion Matrix
        st.markdown("### üîç An√°lisis de Matrices de Confusi√≥n")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### Decision Tree")
            from src.visualization.metrics_viz import plot_confusion_matrix
            st.plotly_chart(
                plot_confusion_matrix(dt_metrics['confusion_matrix'], title="DT - Confusion Matrix"),
                use_container_width=True
            )
        
        with col2:
            st.markdown("#### Random Forest")
            st.plotly_chart(
                plot_confusion_matrix(rf_metrics['confusion_matrix'], title="RF - Confusion Matrix"),
                use_container_width=True
            )
        
        # Interpretaci√≥n
        st.info("""
        **üìñ Interpretaci√≥n de la Confusion Matrix:**
        
        - **True Negatives (TN)**: Muertes correctamente predichas
        - **False Positives (FP)**: Predijimos supervivencia pero murieron (Error Tipo I)
        - **False Negatives (FN)**: Predijimos muerte pero sobrevivieron (Error Tipo II)
        - **True Positives (TP)**: Supervivencias correctamente predichas
        
        Un buen modelo minimiza FP y FN mientras maximiza TN y TP.
        """)
    
    # Tab 3: Feature Importance
    with tabs[2]:
        st.subheader("Comparaci√≥n de Feature Importance")
        
        st.markdown("""
        La importancia de caracter√≠sticas muestra qu√© variables tienen m√°s influencia
        en las predicciones de cada modelo.
        """)
        
        dt_importance = st.session_state['dt_model'].get_feature_importance()
        rf_importance = st.session_state['rf_model'].get_feature_importance()
        
        # Gr√°fico comparativo
        st.plotly_chart(
            plot_feature_importance_comparison(dt_importance, rf_importance),
            use_container_width=True
        )
        
        st.markdown("---")
        
        # Tabla de importancias
        st.markdown("### üìä Tabla de Importancias")
        
        importance_comparison = pd.DataFrame({
            'Feature': list(dt_importance.keys()),
            'DT Importance': list(dt_importance.values()),
            'RF Importance': [rf_importance.get(f, 0) for f in dt_importance.keys()]
        })
        
        importance_comparison['Diferencia'] = (
            importance_comparison['RF Importance'] - importance_comparison['DT Importance']
        )
        
        importance_comparison = importance_comparison.sort_values('RF Importance', ascending=False)
        
        st.dataframe(
            importance_comparison.style.format({
                'DT Importance': '{:.4f}',
                'RF Importance': '{:.4f}',
                'Diferencia': '{:+.4f}'
            }).background_gradient(subset=['RF Importance'], cmap='Greens'),
            use_container_width=True
        )
        
        # Top features de cada modelo
        st.markdown("---")
        st.markdown("### üèÜ Top 3 Features por Modelo")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### üå≥ Decision Tree")
            for i, (feature, imp) in enumerate(list(dt_importance.items())[:3], 1):
                st.metric(f"{i}. {feature}", f"{imp:.4f}")
        
        with col2:
            st.markdown("#### üå≤ Random Forest")
            for i, (feature, imp) in enumerate(list(rf_importance.items())[:3], 1):
                st.metric(f"{i}. {feature}", f"{imp:.4f}")
        
        # An√°lisis de consenso
        st.markdown("---")
        st.markdown("### ü§ù Consenso entre Modelos")
        
        dt_top3 = set(list(dt_importance.keys())[:3])
        rf_top3 = set(list(rf_importance.keys())[:3])
        
        consensus = dt_top3.intersection(rf_top3)
        
        if len(consensus) > 0:
            st.success(f"""
            **‚úÖ Ambos modelos coinciden en que estas features son importantes:**
            
            {', '.join(consensus)}
            
            Esto sugiere que estas caracter√≠sticas son robustamente importantes
            para la predicci√≥n de supervivencia.
            """)
        else:
            st.warning("""
            ‚ö†Ô∏è Los modelos tienen diferencias en las features m√°s importantes.
            Esto puede deberse a la forma diferente en que cada algoritmo eval√∫a la importancia.
            """)
    
    # Tab 4: Rendimiento
    with tabs[3]:
        st.subheader("An√°lisis de Rendimiento y Complejidad")
        
        st.markdown("""
        Comparaci√≥n de caracter√≠sticas t√©cnicas y de rendimiento de ambos modelos.
        """)
        
        # Tabla de caracter√≠sticas
        characteristics = {
            'Caracter√≠stica': [
                'Complejidad de Entrenamiento',
                'Complejidad de Predicci√≥n',
                'Interpretabilidad',
                'Resistencia al Overfitting',
                'Manejo de Ruido',
                'Estabilidad',
                'Uso de Memoria',
                'Paralelizaci√≥n'
            ],
            'Decision Tree': [
                'Baja (O(n log n))',
                'Muy R√°pida (O(log n))',
                'Alta - F√°cil de visualizar',
                'Baja - Propenso',
                'Baja',
                'Baja - Sensible a cambios',
                'Bajo',
                'No'
            ],
            'Random Forest': [
                'Media-Alta (k √ó O(n log n))',
                'Media (k √ó O(log n))',
                'Media-Baja',
                'Alta - Resistente',
                'Alta',
                'Alta - Robusto',
                'Alto (k √°rboles)',
                'S√≠'
            ]
        }
        
        char_df = pd.DataFrame(characteristics)
        st.dataframe(char_df, use_container_width=True, hide_index=True)
        
        st.markdown("---")
        
        # An√°lisis de complejidad
        st.markdown("### ‚öôÔ∏è Detalles de Configuraci√≥n")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### üå≥ Decision Tree")
            dt_params = st.session_state.get('dt_params', {})
            st.code(f"""
Profundidad M√°xima: {dt_params.get('max_depth', 'N/A')}
Min Samples Split: {dt_params.get('min_samples_split', 'N/A')}
Min Samples Leaf: {dt_params.get('min_samples_leaf', 'N/A')}

√Årbol Real:
- Profundidad: {st.session_state.get('dt_model').get_tree_depth()}
- Hojas: {st.session_state.get('dt_model').get_n_leaves()}
            """)
        
        with col2:
            st.markdown("#### üå≤ Random Forest")
            rf_params = st.session_state.get('rf_params', {})
            ensemble_info = st.session_state.get('rf_model').analyze_ensemble()
            st.code(f"""
N√∫mero de √Årboles: {rf_params.get('n_estimators', 'N/A')}
Profundidad M√°xima: {rf_params.get('max_depth', 'N/A')}
Min Samples Split: {rf_params.get('min_samples_split', 'N/A')}
Min Samples Leaf: {rf_params.get('min_samples_leaf', 'N/A')}

Ensemble:
- Features: {ensemble_info['n_features']}
- Clases: {ensemble_info['n_classes']}
            """)
        
        st.markdown("---")
        
        # Casos de uso recomendados
        st.markdown("### üíº Casos de Uso Recomendados")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.info("""
            **üå≥ Usa Decision Tree cuando:**
            
            - ‚úÖ Necesitas m√°xima interpretabilidad
            - ‚úÖ Quieres explicar cada decisi√≥n
            - ‚úÖ Tienes recursos limitados
            - ‚úÖ El dataset es peque√±o
            - ‚úÖ Necesitas predicciones muy r√°pidas
            - ‚úÖ La simplicidad es prioritaria
            """)
        
        with col2:
            st.success("""
            **üå≤ Usa Random Forest cuando:**
            
            - ‚úÖ Priorizas precisi√≥n sobre interpretabilidad
            - ‚úÖ Tienes suficientes recursos computacionales
            - ‚úÖ El dataset es mediano/grande
            - ‚úÖ Necesitas robustez ante ruido
            - ‚úÖ Quieres reducir overfitting
            - ‚úÖ La producci√≥n requiere estabilidad
            """)
    
    # Tab 5: Conclusiones
    with tabs[4]:
        st.subheader("Conclusiones y Recomendaciones")
        
        # Resumen final
        st.markdown("### üìù Resumen Final")
        
        winner = "Random Forest" if rf_metrics['accuracy'] > dt_metrics['accuracy'] else "Decision Tree"
        
        st.success(f"""
        ### üèÜ Modelo Recomendado: **{winner}**
        
        Bas√°ndonos en el an√°lisis completo de m√©tricas, estabilidad y caracter√≠sticas,
        **{winner}** es el modelo m√°s adecuado para este problema de clasificaci√≥n.
        """)
        
        st.markdown("---")
        
        # An√°lisis detallado
        st.markdown("### üîç An√°lisis Detallado")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### ‚úÖ Fortalezas Identificadas")
            
            if rf_metrics['accuracy'] > dt_metrics['accuracy']:
                st.write("**Random Forest:**")
                st.write("- Mayor accuracy general")
                st.write("- Mejor generalizaci√≥n")
                st.write("- M√°s robusto ante overfitting")
            else:
                st.write("**Decision Tree:**")
                st.write("- Buena precisi√≥n con simplicidad")
                st.write("- F√°cil de interpretar")
                st.write("- R√°pido en entrenamiento y predicci√≥n")
            
            st.write("\n**Decision Tree:**")
            st.write("- M√°xima interpretabilidad")
            st.write("- Visualizaci√≥n clara del proceso")
            st.write("- Bajo uso de recursos")
        
        with col2:
            st.markdown("#### ‚ö†Ô∏è √Åreas de Mejora")
            
            st.write("**Decision Tree:**")
            st.write("- Propenso al sobreajuste")
            st.write("- Menos estable ante cambios en datos")
            st.write("- Puede crear √°rboles muy complejos")
            
            st.write("\n**Random Forest:**")
            st.write("- Menos interpretable que DT")
            st.write("- Mayor costo computacional")
            st.write("- Requiere m√°s recursos de memoria")
        
        st.markdown("---")
        
        # Recomendaciones finales
        st.markdown("### üí° Recomendaciones para Mejoras Futuras")
        
        st.info("""
        **üìà Pr√≥ximos Pasos para Mejorar los Modelos:**
        
        1. **Optimizaci√≥n de Hiperpar√°metros:**
           - Usar GridSearchCV o RandomizedSearchCV
           - Explorar m√°s combinaciones de par√°metros
           - Optimizar espec√≠ficamente para F1-score si las clases est√°n desbalanceadas
        
        2. **Feature Engineering Avanzado:**
           - Crear features de familia (FamilySize, IsAlone)
           - Extraer t√≠tulos de los nombres (Mr., Mrs., Master)
           - Binning inteligente de Age y Fare
        
        3. **Ensemble Avanzado:**
           - Probar Gradient Boosting (XGBoost, LightGBM)
           - Implementar Stacking de modelos
           - Voting Classifier combinando ambos modelos
        
        4. **Validaci√≥n M√°s Robusta:**
           - Usar StratifiedKFold para mejor validaci√≥n
           - Implementar validaci√≥n en datos temporales si aplica
           - An√°lisis de curvas ROC y AUC
        
        5. **Interpretabilidad:**
           - Usar SHAP values para explicar predicciones
           - Implementar LIME para casos individuales
           - Crear visualizaciones interactivas
        """)
        
        st.markdown("---")
        
        # Aplicaci√≥n en el mundo real
        st.markdown("### üåç Aplicaci√≥n en el Mundo Real")
        
        st.warning("""
        **‚ö° Consideraciones para Producci√≥n:**
        
        **Si este fuera un sistema real de predicci√≥n:**
        
        1. **Manejo de Datos Nuevos:**
           - Pipeline de preprocesamiento automatizado
           - Validaci√≥n de datos de entrada
           - Manejo de valores fuera de rango
        
        2. **Monitoreo y Mantenimiento:**
           - Tracking de performance en producci√≥n
           - Detecci√≥n de data drift
           - Re-entrenamiento peri√≥dico
        
        3. **Explicabilidad:**
           - Reportes de decisiones para stakeholders
           - Auditor√≠a de predicciones
           - Cumplimiento de regulaciones (GDPR, etc.)
        
        4. **Optimizaci√≥n:**
           - Reducci√≥n de tama√±o del modelo
           - Optimizaci√≥n de velocidad de inferencia
           - Caching de predicciones frecuentes
        """)
        
        # M√©tricas finales
        st.markdown("---")
        st.markdown("### üéØ M√©tricas Finales del Proyecto")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            best_acc = max(dt_metrics['accuracy'], rf_metrics['accuracy'])
            st.metric("Mejor Accuracy", f"{best_acc:.3f}")
        
        with col2:
            best_f1 = max(dt_metrics['f1_score'], rf_metrics['f1_score'])
            st.metric("Mejor F1-Score", f"{best_f1:.3f}")
        
        with col3:
            improvement = abs(rf_metrics['accuracy'] - dt_metrics['accuracy'])
            st.metric("Mejora Lograda", f"{improvement:.3f}")
        
        with col4:
            avg_acc = (dt_metrics['accuracy'] + rf_metrics['accuracy']) / 2
            st.metric("Accuracy Promedio", f"{avg_acc:.3f}")
        
        st.success("""
        ‚úÖ **Proyecto Completado Exitosamente!**
        
        Hemos implementado, evaluado y comparado dos algoritmos fundamentales de Machine Learning,
        demostrando sus fortalezas y debilidades en un problema real de clasificaci√≥n.
        """)